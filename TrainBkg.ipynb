{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb74a62f-a4a9-4e61-9415-58c8a06f5f75",
   "metadata": {},
   "source": [
    "# Hit classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d61cb5d-7c43-4a94-9e3c-eb2889e69b88",
   "metadata": {},
   "source": [
    "In this notebook we will try to use Keras and XGBoost in order to distinguish between _true_ conversion electron hits and _fake_ conversion electron hits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "52ce5426-86e5-4f6e-a7d5-a847d6e2ce97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import uproot \n",
    "import awkward as ak\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "import tensorflow.keras.layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b18db5-7d46-40ed-9a1b-528d48256097",
   "metadata": {},
   "source": [
    "First of all we use [uproot](https://uproot.readthedocs.io/en/latest/), a library to reading ROOT files in pure Python and NumPy, to open the `trkana` tree in the `TAKK` folder of the `KKSM01.root` file. We only need certain branches, so we apply a filter to read only `de`, `detsh`, `detshmc`, and `demc`. We then apply a mask to our tree to select only good fits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "90450e58-8bce-4fae-be27-97d62d89be18",
   "metadata": {},
   "outputs": [],
   "source": [
    "with uproot.open(\"/Users/brownd/data/39501509/nts.brownd.KKSeed.KKSM.001210_00000008.root\") as file:\n",
    "    trkana = file[\"TAKK\"][\"trkana\"].arrays(filter_name=\"/de|detsh|detshmc|demc/i\")\n",
    "    trkana = trkana[(trkana['de.goodfit']==1)&(trkana['de.status']>0)&(trkana['demc.proc']==167)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81afa96c-4517-4bca-95c5-53ef01a36dc8",
   "metadata": {},
   "source": [
    "Then, we concatenate each hit variables into a single, large numpy array. These arrays are then stacked in a single bi-dimensional array with `np.vstack`, which will be our input dataset used for the training of the machine learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "33b84b76-ff6a-44f2-88d6-39cbeb3def87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570158\n",
      "(570158, 9)\n"
     ]
    }
   ],
   "source": [
    "udt = ak.concatenate(trkana['detsh.udt']).to_numpy()\n",
    "udoca = ak.concatenate(trkana['detsh.udoca']).to_numpy()\n",
    "rdrift = ak.concatenate(trkana['detsh.rdrift']).to_numpy()\n",
    "tottdrift = ak.concatenate(trkana['detsh.tottdrift']).to_numpy()\n",
    "edep = ak.concatenate(trkana['detsh.edep']).to_numpy()\n",
    "udocavar = ak.concatenate(trkana['detsh.udocavar']).to_numpy()\n",
    "wdist = ak.concatenate(trkana['detsh.wdist']).to_numpy()\n",
    "uupos = ak.concatenate(trkana['detsh.uupos']).to_numpy()\n",
    "rho = np.square(ak.concatenate(trkana['detsh.poca.fCoordinates.fX']).to_numpy())\n",
    "rho = np.add(rho,np.square(ak.concatenate(trkana['detsh.poca.fCoordinates.fY']).to_numpy()))\n",
    "rho = np.sqrt(rho)\n",
    "n_events = udt.shape[0]\n",
    "print(n_events)\n",
    "\n",
    "input_dataset = np.vstack((udt,udoca,rdrift,tottdrift,edep,udocavar,wdist,uupos,rho)).T\n",
    "print(np.shape(input_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0167fc47-dd84-4a31-98d0-a0270f04bfd5",
   "metadata": {
    "tags": []
   },
   "source": [
    "Here we then assign a label to each hit as _signal_ or _background_, depending on the Monte Carlo truth information. Since the dimension of  `detshmc.rel._rel` is not guaranteed to be the same as the dimension of `detsh` we need to loop over all the entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e546d312-4d8b-4757-9b0e-7293d9eae321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570158\n"
     ]
    }
   ],
   "source": [
    "mcrel = []\n",
    "for i, this_dt in enumerate(trkana['detsh.udt']):\n",
    "    mcrel.extend(trkana['detshmc.rel._rel'][i][:len(this_dt)])\n",
    "n_mcevents = len(mcrel)\n",
    "print(n_mcevents)\n",
    "    \n",
    "mcrel = np.array(mcrel)\n",
    "signal = mcrel==0\n",
    "bkg = mcrel==-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2e8445-92ff-416f-a9a8-2d071b1f0bb9",
   "metadata": {},
   "source": [
    "In our problem we have a different number of signal and background entries in our input dataset. There are several techniques avaialable for _unbalanced_ datasets. Here we are using the most naive one, which is just using $\\min(N_{sig}, N_{bkg})$ events. Then, we divide our input into the _training_, _validation_, and _test_ datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2ed7b23e-d3ab-4645-a905-c3d4090eb7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5973\n"
     ]
    }
   ],
   "source": [
    "min_len = min(len(input_dataset[signal]), len(input_dataset[bkg]))\n",
    "signal_dataset = input_dataset[signal][:min_len]\n",
    "bkg_dataset = input_dataset[bkg][:min_len]\n",
    "print(min_len)\n",
    "\n",
    "balanced_input = np.concatenate((signal_dataset, bkg_dataset))\n",
    "y_balanced_input = np.concatenate((np.ones(signal_dataset.shape[0]), np.zeros(bkg_dataset.shape[0])))\n",
    "\n",
    "n_variables = balanced_input.shape[1]\n",
    "\n",
    "x_ce_train, x_ce_test, y_ce_train, y_ce_test = train_test_split(balanced_input, y_balanced_input, test_size=0.5, random_state=42)\n",
    "x_ce_test, x_ce_valid, y_ce_test, y_ce_valid = train_test_split(x_ce_test, y_ce_test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414715a1-8fe6-47d2-b856-76e7f09a30c5",
   "metadata": {},
   "source": [
    "## Create and train a multi-layer perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3968ba-51a2-45c8-9882-c989a3f7d691",
   "metadata": {},
   "source": [
    "Here we create a _multi-layer perceptron_ (MLP) model which consists of 3 fully-connected (or _dense_) layers, each one followed by a _dropout_ layer, which helps to avoid overfitting. The model is trained using the [Adam](https://arxiv.org/abs/1412.6980) optimizer and trained for 50 epochs or until the validation loss doesn't improve for 5 epochs (`early_stop`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6be3a800-39dd-41ff-bd78-c5156fd4919c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "187/187 [==============================] - 1s 4ms/step - loss: 6.7308 - accuracy: 0.6154 - val_loss: 1.0008 - val_accuracy: 0.7345\n",
      "Epoch 2/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.7717 - accuracy: 0.7649 - val_loss: 0.6740 - val_accuracy: 0.7934\n",
      "Epoch 3/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.5323 - accuracy: 0.8056 - val_loss: 0.5125 - val_accuracy: 0.8226\n",
      "Epoch 4/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.4589 - accuracy: 0.8138 - val_loss: 0.4709 - val_accuracy: 0.8236\n",
      "Epoch 5/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.4423 - accuracy: 0.8118 - val_loss: 0.4527 - val_accuracy: 0.8276\n",
      "Epoch 6/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.4215 - accuracy: 0.8227 - val_loss: 0.4908 - val_accuracy: 0.8182\n",
      "Epoch 7/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.4204 - accuracy: 0.8255 - val_loss: 0.4148 - val_accuracy: 0.8346\n",
      "Epoch 8/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.4176 - accuracy: 0.8237 - val_loss: 0.4292 - val_accuracy: 0.8336\n",
      "Epoch 9/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.4078 - accuracy: 0.8262 - val_loss: 0.4193 - val_accuracy: 0.8283\n",
      "Epoch 10/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.4062 - accuracy: 0.8255 - val_loss: 0.4079 - val_accuracy: 0.8410\n",
      "Epoch 11/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.3905 - accuracy: 0.8344 - val_loss: 0.4008 - val_accuracy: 0.8420\n",
      "Epoch 12/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.4296 - accuracy: 0.8162 - val_loss: 0.3996 - val_accuracy: 0.8413\n",
      "Epoch 13/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.4221 - accuracy: 0.8234 - val_loss: 0.4351 - val_accuracy: 0.8112\n",
      "Epoch 14/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.3764 - accuracy: 0.8388 - val_loss: 0.4012 - val_accuracy: 0.8323\n",
      "Epoch 15/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.3824 - accuracy: 0.8381 - val_loss: 0.4085 - val_accuracy: 0.8416\n",
      "Epoch 16/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.3797 - accuracy: 0.8388 - val_loss: 0.3816 - val_accuracy: 0.8504\n",
      "Epoch 17/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.3753 - accuracy: 0.8389 - val_loss: 0.3877 - val_accuracy: 0.8447\n",
      "Epoch 18/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.3834 - accuracy: 0.8378 - val_loss: 0.3865 - val_accuracy: 0.8510\n",
      "Epoch 19/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.3716 - accuracy: 0.8456 - val_loss: 0.3945 - val_accuracy: 0.8346\n",
      "Epoch 20/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.3686 - accuracy: 0.8438 - val_loss: 0.3696 - val_accuracy: 0.8544\n",
      "Epoch 21/200\n",
      "187/187 [==============================] - 1s 4ms/step - loss: 0.3760 - accuracy: 0.8403 - val_loss: 0.4011 - val_accuracy: 0.8333\n",
      "Epoch 22/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.3649 - accuracy: 0.8466 - val_loss: 0.3637 - val_accuracy: 0.8537\n",
      "Epoch 23/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.3731 - accuracy: 0.8471 - val_loss: 0.3609 - val_accuracy: 0.8560\n",
      "Epoch 24/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.3712 - accuracy: 0.8450 - val_loss: 0.3741 - val_accuracy: 0.8430\n",
      "Epoch 25/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.3596 - accuracy: 0.8493 - val_loss: 0.3878 - val_accuracy: 0.8396\n",
      "Epoch 26/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.3641 - accuracy: 0.8450 - val_loss: 0.3571 - val_accuracy: 0.8581\n",
      "Epoch 27/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.3506 - accuracy: 0.8543 - val_loss: 0.3416 - val_accuracy: 0.8661\n",
      "Epoch 28/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.3687 - accuracy: 0.8425 - val_loss: 0.3576 - val_accuracy: 0.8487\n",
      "Epoch 29/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.3541 - accuracy: 0.8505 - val_loss: 0.3414 - val_accuracy: 0.8594\n",
      "Epoch 30/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.3469 - accuracy: 0.8540 - val_loss: 0.3476 - val_accuracy: 0.8607\n",
      "Epoch 31/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.3455 - accuracy: 0.8537 - val_loss: 0.3323 - val_accuracy: 0.8704\n",
      "Epoch 32/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.3432 - accuracy: 0.8532 - val_loss: 0.3410 - val_accuracy: 0.8621\n",
      "Epoch 33/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.3482 - accuracy: 0.8543 - val_loss: 0.3774 - val_accuracy: 0.8420\n",
      "Epoch 34/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.3347 - accuracy: 0.8615 - val_loss: 0.3246 - val_accuracy: 0.8758\n",
      "Epoch 35/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.3247 - accuracy: 0.8647 - val_loss: 0.3247 - val_accuracy: 0.8741\n",
      "Epoch 36/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.3244 - accuracy: 0.8666 - val_loss: 0.3228 - val_accuracy: 0.8738\n",
      "Epoch 37/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.3508 - accuracy: 0.8584 - val_loss: 0.3712 - val_accuracy: 0.8560\n",
      "Epoch 38/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.3319 - accuracy: 0.8651 - val_loss: 0.3152 - val_accuracy: 0.8791\n",
      "Epoch 39/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.3194 - accuracy: 0.8627 - val_loss: 0.3132 - val_accuracy: 0.8768\n",
      "Epoch 40/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.3136 - accuracy: 0.8676 - val_loss: 0.3182 - val_accuracy: 0.8761\n",
      "Epoch 41/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.3096 - accuracy: 0.8736 - val_loss: 0.3591 - val_accuracy: 0.8637\n",
      "Epoch 42/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.3021 - accuracy: 0.8803 - val_loss: 0.3089 - val_accuracy: 0.8838\n",
      "Epoch 43/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.3245 - accuracy: 0.8669 - val_loss: 0.3882 - val_accuracy: 0.8108\n",
      "Epoch 44/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.3117 - accuracy: 0.8731 - val_loss: 0.3026 - val_accuracy: 0.8788\n",
      "Epoch 45/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.2960 - accuracy: 0.8877 - val_loss: 0.3221 - val_accuracy: 0.8604\n",
      "Epoch 46/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.2901 - accuracy: 0.8815 - val_loss: 0.2839 - val_accuracy: 0.8932\n",
      "Epoch 47/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.2749 - accuracy: 0.8920 - val_loss: 0.3040 - val_accuracy: 0.8822\n",
      "Epoch 48/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.2747 - accuracy: 0.8955 - val_loss: 0.2638 - val_accuracy: 0.9086\n",
      "Epoch 49/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.2458 - accuracy: 0.9074 - val_loss: 0.2571 - val_accuracy: 0.9093\n",
      "Epoch 50/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.2314 - accuracy: 0.9138 - val_loss: 0.3062 - val_accuracy: 0.8822\n",
      "Epoch 51/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.2211 - accuracy: 0.9186 - val_loss: 0.2422 - val_accuracy: 0.9123\n",
      "Epoch 52/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.2111 - accuracy: 0.9195 - val_loss: 0.2315 - val_accuracy: 0.9150\n",
      "Epoch 53/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.1971 - accuracy: 0.9310 - val_loss: 0.2065 - val_accuracy: 0.9287\n",
      "Epoch 54/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.2068 - accuracy: 0.9221 - val_loss: 0.2179 - val_accuracy: 0.9203\n",
      "Epoch 55/200\n",
      "187/187 [==============================] - 1s 5ms/step - loss: 0.2008 - accuracy: 0.9275 - val_loss: 0.2008 - val_accuracy: 0.9287\n",
      "Epoch 56/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.1918 - accuracy: 0.9297 - val_loss: 0.1941 - val_accuracy: 0.9351\n",
      "Epoch 57/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.1946 - accuracy: 0.9334 - val_loss: 0.1902 - val_accuracy: 0.9351\n",
      "Epoch 58/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.1901 - accuracy: 0.9320 - val_loss: 0.1825 - val_accuracy: 0.9394\n",
      "Epoch 59/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.1925 - accuracy: 0.9273 - val_loss: 0.1870 - val_accuracy: 0.9364\n",
      "Epoch 60/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.1739 - accuracy: 0.9386 - val_loss: 0.1830 - val_accuracy: 0.9377\n",
      "Epoch 61/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.1733 - accuracy: 0.9387 - val_loss: 0.1806 - val_accuracy: 0.9361\n",
      "Epoch 62/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.1738 - accuracy: 0.9386 - val_loss: 0.1800 - val_accuracy: 0.9397\n",
      "Epoch 63/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.1710 - accuracy: 0.9376 - val_loss: 0.1969 - val_accuracy: 0.9357\n",
      "Epoch 64/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.1698 - accuracy: 0.9392 - val_loss: 0.1826 - val_accuracy: 0.9377\n",
      "Epoch 65/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.1763 - accuracy: 0.9392 - val_loss: 0.1715 - val_accuracy: 0.9424\n",
      "Epoch 66/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.1721 - accuracy: 0.9386 - val_loss: 0.1804 - val_accuracy: 0.9407\n",
      "Epoch 67/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.1710 - accuracy: 0.9411 - val_loss: 0.1859 - val_accuracy: 0.9377\n",
      "Epoch 68/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.1732 - accuracy: 0.9364 - val_loss: 0.1743 - val_accuracy: 0.9387\n",
      "Epoch 69/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.1731 - accuracy: 0.9379 - val_loss: 0.1753 - val_accuracy: 0.9404\n",
      "Epoch 70/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.1735 - accuracy: 0.9419 - val_loss: 0.1708 - val_accuracy: 0.9461\n",
      "Epoch 71/200\n",
      "187/187 [==============================] - 1s 4ms/step - loss: 0.1667 - accuracy: 0.9409 - val_loss: 0.2010 - val_accuracy: 0.9280\n",
      "Epoch 72/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.1739 - accuracy: 0.9429 - val_loss: 0.1861 - val_accuracy: 0.9377\n",
      "Epoch 73/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.1668 - accuracy: 0.9411 - val_loss: 0.1848 - val_accuracy: 0.9394\n",
      "Epoch 74/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.1717 - accuracy: 0.9419 - val_loss: 0.1709 - val_accuracy: 0.9481\n",
      "Epoch 75/200\n",
      "187/187 [==============================] - 1s 3ms/step - loss: 0.1705 - accuracy: 0.9412 - val_loss: 0.1869 - val_accuracy: 0.9320\n"
     ]
    }
   ],
   "source": [
    "opt = Adam(learning_rate=1e-3)\n",
    "model_ce = Sequential(\n",
    "    [\n",
    "        Dense(n_variables+1, activation='relu', input_shape=(n_variables,)),\n",
    "        Dense(n_variables+1, activation='relu'),\n",
    "        Dense(n_variables+1, activation='relu'),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ]\n",
    ")\n",
    "model_ce.compile(loss='binary_crossentropy',\n",
    "                 metrics='accuracy',\n",
    "                 optimizer=opt)\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5)\n",
    "history_ce = model_ce.fit(x_ce_train, y_ce_train,\n",
    "                          batch_size=32,\n",
    "                          epochs=200,\n",
    "                          verbose=1,\n",
    "                          validation_data=(x_ce_valid, y_ce_valid),\n",
    "                          callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78fb06e-22e5-4ecb-b2c5-48b591268733",
   "metadata": {},
   "source": [
    "## Create and train a Boosted Decision Tree\n",
    "Here, instead of using a MLP, we use a [_Gradient Boosted Decision Tree_](https://xgboost.readthedocs.io/en/stable/) (BDT) to distinguish between signal (true CE hits) and background (fake CE hits). We use the defualt hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "698e5894-b4e3-405c-a99b-c76b2f12403b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.300000012,\n",
       "              max_bin=256, max_cat_threshold=64, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.300000012,\n",
       "              max_bin=256, max_cat_threshold=64, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy='depthwise', importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_bin=256, max_cat_threshold=64, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0, ...)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xgboost = XGBClassifier()\n",
    "model_xgboost.fit(x_ce_train, y_ce_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7aa6212-21f7-46c8-b7af-dab07ced4269",
   "metadata": {},
   "source": [
    "Here we can finally apply our two models (the MLP and the BDT) to our test datasets and create the corresponding ROC curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3dcbef70-e875-40dd-8a8f-5a66fc32fb1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction_ce = model_ce.predict(x_ce_test).ravel()\n",
    "fpr_ce, tpr_ce, th_ce = roc_curve(y_ce_test,  prediction_ce)\n",
    "auc_ce = roc_auc_score(y_ce_test, prediction_ce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cce6a838-1a4c-41e3-a2bb-46a270ad6d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_xgboost = model_xgboost.predict_proba(x_ce_test)[:,1]\n",
    "fpr_xgboost, tpr_xgboost, th_xgboost = roc_curve(y_ce_test,  prediction_xgboost)\n",
    "auc_xgboost = roc_auc_score(y_ce_test, prediction_xgboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f392a2-223f-4a47-81de-45dc56b8e42d",
   "metadata": {},
   "source": [
    "The plot of the ROC curves clearly shows that the BDT outperforms the MLP. In principle, however, it should be possible to improve the MLP performances by optimizing the hyperparameters (learning rate, hidden layers, activation functions, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "def9b80f-d130-4ac0-bc19-ea03de7032f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "ax.plot(tpr_ce,1-fpr_ce,label=f'MLP AUC: {auc_ce:.2f}')\n",
    "ax.plot(tpr_xgboost,1-fpr_xgboost,label=f'BDT AUC: {auc_xgboost:.2f}')\n",
    "\n",
    "ax.legend()\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.set_xlabel(\"Signal efficiency\")\n",
    "ax.set_ylabel(\"Background rejection\")\n",
    "ax.set_xlim(0,1.05)\n",
    "ax.set_ylim(0,1.05)\n",
    "fig.savefig(\"truece.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "85abcc01-fbda-425c-b144-134519e20345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_25 (Dense)            (None, 10)                100       \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 331\n",
      "Trainable params: 331\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_ce.summary()\n",
    "model_ce.save(\"TrainBkg.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd3a97a-d792-44ba-988a-bd41f9182be3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KKTrain",
   "language": "python",
   "name": "kktrain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
